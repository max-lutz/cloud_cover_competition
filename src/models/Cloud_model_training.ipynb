{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cloud model training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ezXwtflRecMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994685c3-5358-4559-9c52-a0c099f57438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: line_profiler in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: IPython>=0.13 in /usr/local/lib/python3.7/dist-packages (from line_profiler) (5.5.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (4.4.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=0.13->line_profiler) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=0.13->line_profiler) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython>=0.13->line_profiler) (0.7.0)\n",
            "Requirement already satisfied: line_profiler in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: IPython>=0.13 in /usr/local/lib/python3.7/dist-packages (from line_profiler) (5.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13->line_profiler) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=0.13->line_profiler) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=0.13->line_profiler) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython>=0.13->line_profiler) (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio -q\n",
        "!pip install pandas_path --quiet\n",
        "!pip install line_profiler\n",
        "\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas_path import path\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import rasterio\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy.ma as ma\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "!pip install line_profiler\n",
        "\n",
        "import cv2\n",
        "import albumentations\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "import keras.backend as K\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "pd.set_option('max_colwidth', 400)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeYKGFyBevuE",
        "outputId": "c946f296-8693-4817-9d95-f16008a86363"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pqqXEw8c6HnZ",
        "outputId": "ed46da2c-5a6c-4b4b-cfa1-799ee666379a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data path"
      ],
      "metadata": {
        "id": "-PNhcawnqlMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 512\n",
        "\n",
        "DATA_DIR = Path.cwd().parent / \"content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train\"\n",
        "TRAIN_FEATURES = DATA_DIR / \"train_features\"\n",
        "TRAIN_LABELS = DATA_DIR / \"train_labels\"\n",
        "\n",
        "BANDS = [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
        "\n",
        "train_meta = pd.read_csv(DATA_DIR / \"train_metadata_updated.csv\", index_col=0)"
      ],
      "metadata": {
        "id": "cE_P-zuTfsH7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_paths(df, feature_dir, label_dir=None, bands=BANDS):\n",
        "    \"\"\"\n",
        "    Given dataframe with a column for chip_id, returns a dataframe with a column\n",
        "    added indicating the path to each band's TIF image as \"{band}_path\", eg \"B02_path\".\n",
        "    A column is also added to the dataframe with paths to the label TIF, if the\n",
        "    path to the labels directory is provided.\n",
        "    \"\"\"\n",
        "    for band in bands:\n",
        "        df[f\"{band}_path\"] = \"\"\n",
        "\n",
        "    for i in range(len(df)):\n",
        "      for band in bands:\n",
        "          df[f\"{band}_path\"][i] = feature_dir / df[\"chip_id\"][i] / f\"{band}.tif\"\n",
        "          #assert df[f\"{band}_path\"].path.exists().all()\n",
        "      if label_dir is not None:\n",
        "          df[\"label_path\"][i] = label_dir / (df[\"chip_id\"][i] + \".tif\")\n",
        "          #assert df[\"label_path\"].path.exists().all()\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "ppmlJMidOeRQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_meta = add_paths(train_meta, TRAIN_FEATURES, TRAIN_LABELS, bands=BANDS)"
      ],
      "metadata": {
        "id": "h6raE7VKPC2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99bca3a-95ca-401c-bf97-064e5f1538bc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_meta.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "ODAFx0_Cie2k",
        "outputId": "2c5a8fb4-77a5-4985-8820-eeaf14097530"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cd78d12b-b02e-43e7-aac1-2af97fbfd042\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chip_id</th>\n",
              "      <th>location</th>\n",
              "      <th>datetime</th>\n",
              "      <th>cloudpath</th>\n",
              "      <th>B02_path</th>\n",
              "      <th>B03_path</th>\n",
              "      <th>B04_path</th>\n",
              "      <th>B08_path</th>\n",
              "      <th>label_path</th>\n",
              "      <th>cloud_cover</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adwp</td>\n",
              "      <td>Chifunfu</td>\n",
              "      <td>2020-04-29T08:20:47Z</td>\n",
              "      <td>az://./train_features/adwp</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwp/B02.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwp/B03.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwp/B04.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwp/B08.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_labels/adwp.tif</td>\n",
              "      <td>0.479294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>adwu</td>\n",
              "      <td>Chifunfu</td>\n",
              "      <td>2020-04-29T08:20:47Z</td>\n",
              "      <td>az://./train_features/adwu</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwu/B02.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwu/B03.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwu/B04.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwu/B08.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_labels/adwu.tif</td>\n",
              "      <td>0.636658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adwz</td>\n",
              "      <td>Chifunfu</td>\n",
              "      <td>2020-04-29T08:20:47Z</td>\n",
              "      <td>az://./train_features/adwz</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwz/B02.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwz/B03.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwz/B04.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adwz/B08.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_labels/adwz.tif</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>adxp</td>\n",
              "      <td>Chifunfu</td>\n",
              "      <td>2020-04-29T08:20:47Z</td>\n",
              "      <td>az://./train_features/adxp</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adxp/B02.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adxp/B03.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adxp/B04.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/adxp/B08.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_labels/adxp.tif</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>aeaj</td>\n",
              "      <td>Chifunfu</td>\n",
              "      <td>2020-04-29T08:20:47Z</td>\n",
              "      <td>az://./train_features/aeaj</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/aeaj/B02.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/aeaj/B03.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/aeaj/B04.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_features/aeaj/B08.tif</td>\n",
              "      <td>/content/drive/MyDrive/DATA_SCIENCE/data_google_colab/cloud_cover/raw/train/train_labels/aeaj.tif</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd78d12b-b02e-43e7-aac1-2af97fbfd042')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd78d12b-b02e-43e7-aac1-2af97fbfd042 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd78d12b-b02e-43e7-aac1-2af97fbfd042');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  chip_id  ... cloud_cover\n",
              "0    adwp  ...    0.479294\n",
              "1    adwu  ...    0.636658\n",
              "2    adwz  ...    1.000000\n",
              "3    adxp  ...    1.000000\n",
              "4    aeaj  ...    1.000000\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the data"
      ],
      "metadata": {
        "id": "i9tY4w_Sqonp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_filenames = pd.read_csv(DATA_DIR / \"test_split.csv\")['location'].to_list()\n",
        "test_filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sBRGFiblY5L",
        "outputId": "b1d67a53-ef6f-4497-83af-81cf4be0f24c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Adelaide',\n",
              " 'Alto Hama',\n",
              " 'Angkor Wat',\n",
              " 'Australia - Central',\n",
              " 'Australia - North West',\n",
              " 'Bambesa',\n",
              " 'Bechar',\n",
              " 'Bor',\n",
              " 'Cabo Verdo',\n",
              " 'Chifunfu',\n",
              " 'Chingola',\n",
              " 'Ecuador',\n",
              " 'Eritrea',\n",
              " 'Gabon',\n",
              " 'Ghana',\n",
              " 'Harare']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = train_meta.loc[~train_meta['location'].isin(test_filenames)].iloc[:, 4:-1]\n",
        "df_test = train_meta.loc[train_meta['location'].isin(test_filenames)].iloc[:, 4:-1]\n",
        "\n",
        "print(\"Test data ratio\", round(100*len(df_test)/len(train_meta), 2), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn9rhfctlY2W",
        "outputId": "7f2c7627-95e7-4bce-f6ca-c4882cc165c0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data ratio 20.66 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.reset_index(drop=True)\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "df_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0PosK5CqCvj",
        "outputId": "e9c95c4a-af48-49d6-9137-8cb82462f3c3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['B02_path', 'B03_path', 'B04_path', 'B08_path', 'label_path'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare loading the data"
      ],
      "metadata": {
        "id": "MGSaqM38mKK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_label(df, image_index):\n",
        "    image = np.zeros((512,512,1))\n",
        "    with rasterio.open(df['label_path'][image_index]) as img:            \n",
        "        image[:,:,0] = img.read(1)\n",
        "    return image\n",
        "\n",
        "def load_features(df, image_index):\n",
        "    image = np.zeros((512,512,4))\n",
        "    for i, band in enumerate(['B02_path', 'B03_path', 'B04_path', 'B08_path']):\n",
        "        with rasterio.open(df[band][image_index]) as img:            \n",
        "            image[:,:,i] = img.read(1)\n",
        "    return image\n",
        "\n",
        "def load_multiple_label(df, image_indexes):\n",
        "    image = np.zeros((len(image_indexes),512,512,1))\n",
        "    for np_idx, idx in enumerate(image_indexes):\n",
        "      with rasterio.open(df['label_path'][idx]) as img:            \n",
        "          image[np_idx,:,:,0] = img.read(1)\n",
        "    return image\n",
        "\n",
        "def load_multiple_features(df, image_indexes):\n",
        "    image = np.zeros((len(image_indexes), 512,512,4))\n",
        "    for np_idx, idx in enumerate(image_indexes):\n",
        "      for i, band in enumerate(['B02_path', 'B03_path', 'B04_path', 'B08_path']):\n",
        "          with rasterio.open(df[band][idx]) as img:            \n",
        "              image[np_idx, :,:,i] = img.read(1)\n",
        "    return image"
      ],
      "metadata": {
        "id": "bmhPI-dSUK4A"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "  def __init__(self, df, batch_size):\n",
        "    self.df = df\n",
        "    self.batch_size = batch_size\n",
        "    \n",
        "    \n",
        "  def __len__(self):\n",
        "    return (np.ceil(len(self.df) / float(self.batch_size))).astype(np.int)\n",
        "  \n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    batch_indexes_list = self.df.loc[self.df.index.isin(range(idx * batch_size,(idx+1) * batch_size))].index.to_list()\n",
        "    X = load_multiple_features(self.df, batch_indexes_list)\n",
        "    y = load_multiple_label(self.df, batch_indexes_list)\n",
        "\n",
        "    return X,y"
      ],
      "metadata": {
        "id": "5r-Rr8uilYn2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train[0:254]\n",
        "df_test = df_test[0:64]"
      ],
      "metadata": {
        "id": "UpvVISmo5us9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_batch_generator = My_Custom_Generator(df_train, batch_size)\n",
        "val_batch_generator = My_Custom_Generator(df_test, batch_size)"
      ],
      "metadata": {
        "id": "sXgJy-OjXY0p"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare model"
      ],
      "metadata": {
        "id": "mr26-LZMXVIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://gist.github.com/wassname/7793e2058c5c9dacb5212c0ac0b18a8a\n",
        "def DiceLoss_square(y_true, y_pred, smooth=1):\n",
        "  #create the missing data mask\n",
        "  mask = tf.math.not_equal(y_true, 255)\n",
        "  #apply the mask\n",
        "  y_true = tf.boolean_mask(y_true, mask)\n",
        "  y_pred = tf.boolean_mask(y_pred, mask)\n",
        "\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  intersection = K.sum(K.abs(y_true_f * y_pred_f))\n",
        "  return 1-((2. * intersection + smooth) / (K.sum(K.square(y_true_f),-1) + K.sum(K.square(y_pred_f),-1) + smooth))\n",
        "\n",
        "def DiceLoss(y_true, y_pred, smooth=1):\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true * y_pred)\n",
        "  return 1-((2. * intersection + smooth) / (K.sum(y_true) + K.sum(y_pred) + smooth))"
      ],
      "metadata": {
        "id": "MLdapOZ0ZANu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def IOU_coef(y_true, y_pred):\n",
        "  #create the missing data mask\n",
        "  mask = tf.math.not_equal(y_true, 255)\n",
        "  #apply the mask\n",
        "  y_true = tf.boolean_mask(y_true, mask)\n",
        "  y_pred = tf.boolean_mask(y_pred, mask)\n",
        "\n",
        "  #make all values > 0.5 a 1 and all others a 0\n",
        "  y_pred = tf.cast((y_pred > 0.5), dtype=tf.float32)\n",
        "  #y_pred = tf.math.multiply(tf.math.greater(y_pred, 0.5),1.0)\n",
        "\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true_f * y_pred_f)\n",
        "  return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "# https://www.youtube.com/watch?v=BNPW1mYbgS4\n",
        "def IOULoss(y_true, y_pred):\n",
        "    return -IOU_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "xpDuQ3YiZASv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
        "    # first layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    # second layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(x)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "uMwo0bhqrg-N"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
        "    # contracting path\n",
        "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "    p1 = Dropout(dropout*0.5)(p1)\n",
        "\n",
        "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "\n",
        "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "\n",
        "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "    \n",
        "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "    # expansive path\n",
        "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "VuXEekn7rg3b"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input((img_size, img_size, 4), name='img')\n",
        "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
        "\n",
        "model.compile(optimizer=Adam(), loss=DiceLoss_square, metrics=[IOU_coef])\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "35w9mGOJXmrs"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
        "    ModelCheckpoint('unet_diceloss_square.h5', verbose=1, save_best_only=True, save_weights_only=False)\n",
        "]"
      ],
      "metadata": {
        "id": "pB-fspEvXmvD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_model():\n",
        "  model.fit(train_batch_generator,\n",
        "            steps_per_epoch = int(len(train_batch_generator) // batch_size),\n",
        "            epochs = 1,\n",
        "            verbose = 1,\n",
        "            callbacks=callbacks,\n",
        "            validation_data = val_batch_generator,\n",
        "            validation_steps = int(len(val_batch_generator) // batch_size))"
      ],
      "metadata": {
        "id": "WLlSyyugXmzD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext line_profiler\n",
        "%lprun -f fit_model fit_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TztKDWt0Xm1Q",
        "outputId": "57a7c269-ccd4-440d-c622-85df666852b7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The line_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext line_profiler\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.1171 - IOU_coef: 0.7978 \n",
            "Epoch 00001: val_loss did not improve from 0.06624\n",
            "4/4 [==============================] - 85s 27s/step - loss: 0.1171 - IOU_coef: 0.7978 - val_loss: 0.0717 - val_IOU_coef: 0.8634 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_batch_generator,\n",
        "            steps_per_epoch = int(len(train_batch_generator) // batch_size),\n",
        "            epochs = 1,\n",
        "            verbose = 1,\n",
        "            callbacks=callbacks,\n",
        "            validation_data = val_batch_generator,\n",
        "            validation_steps = int(len(val_batch_generator) // batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKtyRdn0ddAV",
        "outputId": "bd30133b-84ed-43dd-a630-289cd30827d2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - ETA: 0s - loss: 0.1904 - IOU_coef: 0.6764 \n",
            "Epoch 00001: val_loss improved from inf to 0.06771, saving model to unet_diceloss_square.h5\n",
            "4/4 [==============================] - 156s 42s/step - loss: 0.1904 - IOU_coef: 0.6764 - val_loss: 0.0677 - val_IOU_coef: 0.8629 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa8df667150>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}